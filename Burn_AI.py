import gradio as gr
import torch
from torchvision import transforms
from PIL import Image
import google.generativeai as genai
import os
from dotenv import load_dotenv
import time

# --- 1. ç’°å¢ƒèˆ‡è¨­å®š ---
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    print("è­¦å‘Š: æœªåµæ¸¬åˆ° GEMINI_API_KEYï¼Œè«‹æª¢æŸ¥ .env æª”æ¡ˆã€‚")
else:
    genai.configure(api_key=GEMINI_API_KEY)

# è¨­å®šè£ç½®
device = torch.device("cpu")

# --- 2. è¼‰å…¥æ¨¡å‹ ---
# ä½¿ç”¨ TorchScript è¼‰å…¥å„ªåŒ–å¾Œçš„ç§»å‹•ç«¯æ¨¡å‹
MODEL_PATH = "model_mobile.ptl"
try:
    model = torch.jit.load(MODEL_PATH, map_location=device)
    model.eval()
    print(f"æˆåŠŸè¼‰å…¥æ¨¡å‹: {MODEL_PATH}")
except Exception as e:
    print(f"éŒ¯èª¤: ç„¡æ³•è¼‰å…¥æ¨¡å‹ {MODEL_PATH}ã€‚è«‹ç¢ºèªæª”æ¡ˆæ˜¯å¦å­˜åœ¨ã€‚éŒ¯èª¤è¨Šæ¯: {e}")
    model = None

# å½±åƒå‰è™•ç† (éœ€èˆ‡è¨“ç·´æ™‚ä¸€è‡´)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

class_names = ['1st Degree (ä¸€ç´šç‡™å‚·)', '2nd Degree (äºŒç´šç‡™å‚·)', '3rd Degree (ä¸‰ç´šç‡™å‚·)']

# --- 3. å¤šèªè¨€ä»‹é¢æ–‡å­— ---
LANG_TEXT = {
    "ç¹é«”ä¸­æ–‡": {
        "title": "ğŸ”¥ ç‡’ç‡™å‚·ç­‰ç´šè¾¨è­˜èˆ‡é†«è­·æŒ‡å°ç³»çµ±",
        "header_desc": "è«‹ä¸Šå‚³ç‡™å‚·ç…§ç‰‡æˆ–ä½¿ç”¨é¡é ­æ‹æ”ï¼Œç³»çµ±å°‡åˆ†æç‡™å‚·ç­‰ç´šä¸¦æä¾›é†«è­·å»ºè­°ã€‚",
        "input_label": "ä¸Šå‚³æˆ–æ‹æ”ç…§ç‰‡",
        "age_label": "å¹´é½¡",
        "age_placeholder": "é¸å¡«",
        "cause_label": "ç‡™å‚·åŸå› ",
        "cause_placeholder": "é¸å¡«ï¼Œä¾‹å¦‚ï¼šç†±æ°´ã€åŒ–å­¸ç‰©è³ªã€ç«",
        "analyze_btn": "é–‹å§‹åˆ†æ",
        "result_label": "è¾¨è­˜çµæœ",
        "advice_label": "é†«è­·å»ºè­°",
        "loading": "åˆ†æä¸­ï¼Œè«‹ç¨å€™...",
        "error_no_image": "è«‹å…ˆæä¾›ç…§ç‰‡ï¼",
        "error_model": "æ¨¡å‹æœªè¼‰å…¥ï¼Œç„¡æ³•åˆ†æã€‚",
        "disclaimer": """
### âš ï¸ å…è²¬è²æ˜
æœ¬ç³»çµ±åƒ…ä¾›è¼”åŠ©åƒè€ƒï¼Œ**çµ•éå°ˆæ¥­é†«ç™‚è¨ºæ–·**ã€‚
è¾¨è­˜çµæœå¯èƒ½å­˜åœ¨èª¤å·®ï¼Œè‹¥å‚·å‹¢åš´é‡ã€ç¯„åœå»£å¤§æˆ–ä½æ–¼è‡‰éƒ¨ã€é—œç¯€ç­‰é‡è¦éƒ¨ä½ï¼Œ**è«‹ç«‹å³å°±é†«æˆ–æ’¥æ‰“ç·Šæ€¥æ•‘è­·é›»è©±**ã€‚
ä½¿ç”¨æœ¬ç³»çµ±å³ä»£è¡¨æ‚¨åŒæ„è‡ªè¡Œæ‰¿æ“”ç›¸é—œé¢¨éšªã€‚
"""
    },
    "English": {
        "title": "ğŸ”¥ Burn Injury Classification & Medical Advice System",
        "header_desc": "Upload a photo or use camera. The system will classify the burn degree and provide advice.",
        "input_label": "Upload or Capture Image",
        "age_label": "Age",
        "age_placeholder": "Optional",
        "cause_label": "Cause of Burn",
        "cause_placeholder": "Optional, e.g., Hot Water, Chemical, Fire",
        "analyze_btn": "Analyze",
        "result_label": "Classification Result",
        "advice_label": "Medical Advice",
        "loading": "Analyzing, please wait...",
        "error_no_image": "Please provide an image first!",
        "error_model": "Model not loaded.",
        "disclaimer": """
### âš ï¸ Disclaimer
This system is for reference only and **is NOT a professional medical diagnosis**.
Results may be inaccurate. If the injury is severe, extensive, or on sensitive areas (face, joints), **seek immediate medical attention**.
By using this system, you agree to assume all related risks.
"""
    },
    "æ—¥æœ¬èª": {
        "title": "ğŸ”¥ ç†±å‚·æ·±åº¦åˆ¤å®šãƒ»å¿œæ€¥å‡¦ç½®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚·ã‚¹ãƒ†ãƒ ",
        "header_desc": "å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯æ’®å½±ã—ã¦ãã ã•ã„ã€‚ç†±å‚·æ·±åº¦ã‚’åˆ¤å®šã—ã€ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚",
        "input_label": "å†™çœŸã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯æ’®å½±",
        "age_label": "å¹´é½¢",
        "age_placeholder": "ä»»æ„",
        "cause_label": "å—å‚·åŸå› ",
        "cause_placeholder": "ä»»æ„ã€ä¾‹ï¼šç†±æ¹¯ã€åŒ–å­¦ç‰©è³ªã€ç«",
        "analyze_btn": "åˆ†æé–‹å§‹",
        "result_label": "åˆ¤å®šçµæœ",
        "advice_label": "åŒ»ç™‚ã‚¢ãƒ‰ãƒã‚¤ã‚¹",
        "loading": "åˆ†æä¸­ã€ãŠå¾…ã¡ãã ã•ã„...",
        "error_no_image": "å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼",
        "error_model": "ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
        "disclaimer": """
### âš ï¸ å…è²¬äº‹é …
æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯å‚è€ƒç”¨ã§ã‚ã‚Šã€**å°‚é–€çš„ãªåŒ»ç™‚è¨ºæ–­ã§ã¯ã‚ã‚Šã¾ã›ã‚“**ã€‚
åˆ¤å®šçµæœã«ã¯èª¤å·®ãŒç”Ÿã˜ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚é‡ç—‡ã®å ´åˆã‚„ã€é¡”ãƒ»é–¢ç¯€ãªã©ã®é‡è¦éƒ¨ä½ã®å ´åˆã¯ã€**ç›´ã¡ã«åŒ»å¸«ã®è¨ºå¯Ÿã‚’å—ã‘ã¦ãã ã•ã„**ã€‚
æœ¬ã‚·ã‚¹ãƒ†ãƒ ã®åˆ©ç”¨ã«ã‚ˆã‚Šç”Ÿã˜ãŸãƒªã‚¹ã‚¯ã¯ã€åˆ©ç”¨è€…ãŒè² ã†ã‚‚ã®ã¨ã—ã¾ã™ã€‚
"""
    }
}

# --- 4. æ ¸å¿ƒé‚è¼¯ ---

def get_gemini_advice(burn_degree, age, cause, language):
    """ä½¿ç”¨ Gemini API ç”Ÿæˆå»ºè­°"""
    if not GEMINI_API_KEY:
        return "Error: API Key not found."

    model_gemini = genai.GenerativeModel('gemini-2.5-flash-lite')
    
    lang_prompt = {
        "ç¹é«”ä¸­æ–‡": "è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚",
        "English": "Please answer in English.",
        "æ—¥æœ¬èª": "æ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚"
    }
    
    prompt = f"""
    You are a medical assistant expert in burn care.
    Patient Info:
    - Burn Degree: {burn_degree}
    - Age: {age if age else "Unknown"}
    - Cause: {cause if cause else "Unknown"}
    
    Task:
    1. Explain what this burn degree means.
    2. Provide immediate first aid steps.
    3. Advise on whether to see a doctor immediately.
    4. Give specific advice based on age and cause if provided.
    
    {lang_prompt.get(language, "Please answer in Traditional Chinese.")}
    Keep the response concise, structured (use Markdown), and empathetic.
    Start with a warning/disclaimer.
    """
    
    try:
        response = model_gemini.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Gemini API Error: {e}"

def process_analysis(image, age, cause, language):
    """è™•ç†åˆ†ææµç¨‹"""
    txt = LANG_TEXT[language]
    
    if image is None:
        return None, txt["error_no_image"]
    
    if model is None:
        return None, txt["error_model"]

    # 1. å½±åƒè¾¨è­˜
    try:
        pil_image = Image.fromarray(image).convert('RGB')
        input_tensor = transform(pil_image).unsqueeze(0).to(device)
        
        with torch.no_grad():
            output = model(input_tensor)
            probabilities = torch.nn.functional.softmax(output[0], dim=0)
        
        # å–å¾—æœ€é«˜ä¿¡å¿ƒåº¦çš„é¡åˆ¥
        top_prob, top_catid = torch.topk(probabilities, 1)
        predicted_class = class_names[top_catid[0].item()]
        confidence = top_prob[0].item()
        
        result_str = f"{predicted_class} ({confidence:.1%})"
        
    except Exception as e:
        return f"Error: {e}", "Classification Failed"

    # 2. LLM å»ºè­°
    advice = get_gemini_advice(predicted_class, age, cause, language)
    
    return result_str, advice

def update_ui_language(language):
    """æ›´æ–°ä»‹é¢èªè¨€æ–‡å­—"""
    t = LANG_TEXT[language]
    return (
        gr.update(value=t["title"]),
        gr.update(value=t["header_desc"]),
        gr.update(label=t["input_label"]),
        gr.update(label=t["age_label"], placeholder=t["age_placeholder"]),
        gr.update(label=t["cause_label"], placeholder=t["cause_placeholder"]),
        gr.update(value=t["analyze_btn"]),
        gr.update(label=t["result_label"]),
        gr.update(label=t["advice_label"]),
        gr.update(value=t["disclaimer"])
    )

def clear_inputs():
    return None, "", "", None, ""

# --- 5. å»ºæ§‹ Gradio ä»‹é¢ ---
with gr.Blocks() as demo:
    
    # ç‹€æ…‹è®Šæ•¸
    current_lang = gr.State("ç¹é«”ä¸­æ–‡")
    
    # æ¨™é¡Œå€ (ä½¿ç”¨ HTML æ¨™ç±¤åŠ ç²—åŠ å¤§)
    title_md = gr.Markdown(f"<h1><b>{LANG_TEXT['ç¹é«”ä¸­æ–‡']['title']}</b></h1>")
    desc_md = gr.Markdown(LANG_TEXT["ç¹é«”ä¸­æ–‡"]["header_desc"])
    
    with gr.Row():
        lang_dropdown = gr.Dropdown(
            choices=["ç¹é«”ä¸­æ–‡", "English", "æ—¥æœ¬èª"],
            value="ç¹é«”ä¸­æ–‡",
            label="Language / èªè¨€ / è¨€èª",
            interactive=True
        )
    
    with gr.Row():
        # å·¦å´è¼¸å…¥å€
        with gr.Column(scale=1):
            img_input = gr.Image(sources=["upload", "webcam"], type="numpy", label=LANG_TEXT["ç¹é«”ä¸­æ–‡"]["input_label"])
            age_input = gr.Textbox(label=LANG_TEXT["ç¹é«”ä¸­æ–‡"]["age_label"], placeholder=LANG_TEXT["ç¹é«”ä¸­æ–‡"]["age_placeholder"])
            cause_input = gr.Textbox(label=LANG_TEXT["ç¹é«”ä¸­æ–‡"]["cause_label"], placeholder=LANG_TEXT["ç¹é«”ä¸­æ–‡"]["cause_placeholder"])
            analyze_btn = gr.Button(LANG_TEXT["ç¹é«”ä¸­æ–‡"]["analyze_btn"], variant="primary")
            clear_btn = gr.Button("Clear / æ¸…é™¤")
            
        # å³å´è¼¸å‡ºå€
        with gr.Column(scale=1):
            result_output = gr.Label(label=LANG_TEXT["ç¹é«”ä¸­æ–‡"]["result_label"])
            advice_output = gr.Markdown(label=LANG_TEXT["ç¹é«”ä¸­æ–‡"]["advice_label"])
            
    # å…è²¬è²æ˜
    disclaimer_md = gr.Markdown(LANG_TEXT["ç¹é«”ä¸­æ–‡"]["disclaimer"])

    # --- äº‹ä»¶ç¶å®š ---
    
    # èªè¨€åˆ‡æ›
    def update_ui_language_wrapper(language):
        updates = update_ui_language(language)
        t = LANG_TEXT[language]
        return (
            f"<h1><b>{t['title']}</b></h1>",
            t["header_desc"],
            gr.update(label=t["input_label"]),
            gr.update(label=t["age_label"], placeholder=t["age_placeholder"]),
            gr.update(label=t["cause_label"], placeholder=t["cause_placeholder"]),
            gr.update(value=t["analyze_btn"]),
            gr.update(label=t["result_label"]),
            gr.update(label=t["advice_label"]),
            t["disclaimer"]
        )

    lang_dropdown.change(
        fn=update_ui_language_wrapper,
        inputs=[lang_dropdown],
        outputs=[title_md, desc_md, img_input, age_input, cause_input, analyze_btn, result_output, advice_output, disclaimer_md]
    )
    
    # åˆ†ææŒ‰éˆ•
    analyze_btn.click(
        fn=process_analysis,
        inputs=[img_input, age_input, cause_input, lang_dropdown],
        outputs=[result_output, advice_output]
    )
    
    # æ¸…é™¤æŒ‰éˆ•
    clear_btn.click(
        fn=clear_inputs,
        inputs=[],
        outputs=[img_input, age_input, cause_input, result_output, advice_output]
    )

if __name__ == "__main__":
    demo.launch(share=True)
